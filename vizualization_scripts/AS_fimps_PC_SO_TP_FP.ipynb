{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "feature_names = pd.read_csv('../processed_data/metafeatures.csv', index_col=0).columns\n",
    "dataset_names = pd.read_csv('../processed_data/HAMMING LOSS example based/regression/performance.csv', index_col=0).index\n",
    "domains = {\n",
    "    \"Text\": [\"ARABIC200\", \"BIBTEX\", \"ENRON\", \"FOODTRUCK\", \"LANGLOG\", \"MEDICAL\", \"NG20\", \"OHSUMED\", \"REUTERSK500\", \"SCENE\", \"STACKEX_CHESS\", \"STACKEX_CS\", \"STACKEX_PHILOSOPHY\", \"TMC2007_500\", \"YELP\", \"DELICIOUS\", \"SLASHDOT\"],\n",
    "    \"Bioinformatics\": [\"GENBASE\", \"GNEGATIVEGO\", \"GNEGATIVEPSEACC\", \"GPOSITIVEGO\", \"GPOSITIVEPSEAAC\", \"HUMANGO\", \"HUMANPSEAAC\", \"PLANTGO\", \"PLANTPSEAAC\", \"PROTEINS_HUMAN\", \"PROTEINS_PLANT\", \"PROTEINS_VIRUS\", \"VIRUSGO\", \"VIRUS_PSEAAC\", \"YEAST\"],\n",
    "    \"Multimedia\": [\"BIRDS\", \"CAL500\", \"COREL5K\", \"EMOTIONS\", \"FLAGS\"],\n",
    "    \"Medical\": [\"CHD_49\", \"ABPM\"],\n",
    "    \"Chemistry\": [\"WATER_QUALITY\"]\n",
    "}\n",
    "\n",
    "# Function to calculate heights for subplots based on domain data\n",
    "def get_heights(domains, df_fimps, row_height=30):\n",
    "    return [len(df_fimps.loc[df_fimps.index.intersection(domain_datasets)]) * row_height for domain, domain_datasets in domains.items()]\n",
    "\n",
    "def generate_plot(df_fimps, domains):\n",
    "    # Create subplot figure with variable row heights\n",
    "    fig = make_subplots(\n",
    "        rows=len(domains),\n",
    "        cols=1,\n",
    "        shared_xaxes=True,\n",
    "        vertical_spacing=0.04,\n",
    "        subplot_titles=list(domains.keys()),\n",
    "        row_heights=get_heights(domains, df_fimps)\n",
    "    )\n",
    "\n",
    "    # Determine global zmin and zmax for consistent color scaling across all plots\n",
    "    zmin = df_fimps.min().min()\n",
    "    zmax = df_fimps.max().max()\n",
    "\n",
    "    # Adding heatmaps to each subplot\n",
    "    for i, (domain, domain_datasets) in enumerate(domains.items(), start=1):\n",
    "        domain_data = df_fimps.loc[df_fimps.index.intersection(domain_datasets)]\n",
    "        fig.add_trace(\n",
    "            go.Heatmap(\n",
    "                z=domain_data.values,\n",
    "                x=domain_data.columns,\n",
    "                y=domain_data.index,\n",
    "                # colorscale=[[0, 'red'], [0.5, 'white'], [1, '#167bb6']],  # Teal pastel blue\n",
    "                colorscale='Reds',\n",
    "                zmin=zmin,\n",
    "                zmax=zmax,\n",
    "                name=domain,\n",
    "                reversescale=True\n",
    "            ),\n",
    "            row=i, col=1\n",
    "        )\n",
    "\n",
    "    # Update layout to make the figure more readable and give equal space for each subplot\n",
    "    fig.update_layout(\n",
    "        # title='SHAP Values Heatmap by Domain',\n",
    "        height=sum(get_heights(domains, df_fimps)),  # Set total height based on the sum of heights\n",
    "        width=900,\n",
    "        autosize=True\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "import os\n",
    "\n",
    "def get_pairwise_targets(run_id, seed, metric, selected_algo):\n",
    "    folder = f\"../{run_id}/seed_{seed}/{metric}/pairwise_classification/single\"\n",
    "    pairs_targets = [(f.split('_')[2], f.split('_')[4].split('.')[0]) for f in os.listdir(folder) if f.startswith(\"performance\")]\n",
    "    filtered_pairs = [ pair for pair in pairs_targets  if selected_algo in pair ]\n",
    "    return filtered_pairs\n",
    "    \n",
    "\n",
    "def get_data_pairwise_classification_single(metric, seed, run_id):\n",
    "    learning_task = 'pairwise_classification'\n",
    "    task_output = 'single'\n",
    "    algo_portfolio = np.load(f'../processed_data/{metric}/algo_portfolio.npy', allow_pickle=True)\n",
    "    print(algo_portfolio)\n",
    "    AS_file = f\"../{run_id}/seed_{seed}/{metric}/AS.csv\"\n",
    "    predicted_algo = pd.read_csv(AS_file)['AS-PC-SO_algo_name']\n",
    "    \n",
    "\n",
    "    data = []\n",
    "    for fold in range(40):\n",
    "        data_fold = []\n",
    "        predicted_algos_fold = predicted_algo.iloc[fold].split(',')\n",
    "        for predicted_algo_fold in predicted_algos_fold: \n",
    "            print(predicted_algo_fold)\n",
    "            pairs = get_pairwise_targets(run_id, seed, metric, predicted_algo_fold)\n",
    "            for pair in pairs:\n",
    "                prediction_pair_file_path = f'../{run_id}/seed_{seed}/{metric}/pairwise_classification/single/predictions/test_predictions_fold_{fold}_{pair[0]}_vs_{pair[1]}.npy'\n",
    "                print(prediction_pair_file_path)\n",
    "                predictions_pair = np.load(prediction_pair_file_path)[0]\n",
    "                shap_pair_file_path = f'../{run_id}/seed_{seed}/{metric}/pairwise_classification/single/shap/test_shap_fold_{fold}_{pair[0]}_vs_{pair[1]}.npy'\n",
    "                shap_pair = np.load(shap_pair_file_path)\n",
    "                if pair[predictions_pair] == predicted_algo_fold:\n",
    "                    print(predictions_pair, pair, predicted_algo_fold)\n",
    "                    shap_fimps = shap_pair[predictions_pair]\n",
    "                    shap_fimps_df = pd.DataFrame(shap_fimps)\n",
    "                    shap_fimps_df = shap_fimps_df.abs()\n",
    "                    print(\"before\", shap_fimps_df)\n",
    "                    shap_fimps_df = shap_fimps_df.rank(axis=1, method='min', ascending=False)\n",
    "                    print(\"after\", shap_fimps_df)\n",
    "                    data_fold.append(list(shap_fimps_df.values[0]))\n",
    "            break\n",
    "        print(data_fold)\n",
    "        data_fold_df = pd.DataFrame(data_fold)\n",
    "        data_fold_df = data_fold_df.mean(axis=0)\n",
    "        print(data_fold_df)\n",
    "\n",
    "\n",
    "        data.append(data_fold_df.values)\n",
    "\n",
    "        # predicted_algo_fold_idx = list(algo_portfolio).index(predicted_algo_fold)\n",
    "        # shap_algo_fold_file_path = f\"../{run_id}/seed_{seed}/{metric}/{learning_task}/{task_output}/shap/test_shap_fold_{fold}.npy\"\n",
    "        # shap_algo_fold = np.load(shap_algo_fold_file_path)[predicted_algo_fold_idx]\n",
    "        # data.append(shap_algo_fold[0])\n",
    "    return pd.DataFrame(data, index=dataset_names, columns=feature_names)\n",
    "\n",
    "\n",
    "# settings\n",
    "metric = \"AUCROC MICRO\"\n",
    "seed = 42\n",
    "run_id = \"results\"\n",
    "\n",
    "df_fimps = get_data_pairwise_classification_single(metric, seed, run_id)\n",
    "generate_plot(df_fimps, domains)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gecco2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
